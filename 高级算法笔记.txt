参考教材中文版，有文字错误，内容其中一部分与课上相同，有一些课上有的它没有：https://static.latexstudio.net/wp-content/uploads/2013/03/main1.pdf

----------------

1. 最优性

最坏复杂度：在所有可能的n规模输入中，算法的最大操作次数（上限）。它是一个关于n的函数，记作W(n)
平均复杂度：算法运行时间的期望值，加权平均，即 ∑ 某种输入出现的概率*耗时
问题的复杂度的下界：
    一类（解决同一个给定问题的）算法至少要执行F次基本操作
    思路一：信息论。如找最大值，找到最大值时，其他n-1个数肯定要输过，也就至少要n-1份输信息。一次比较最多提供一份输信息。如果某算法只进行了n-2次比较操作，一定能找到一个输入使得此算法输出错误结果
    思路二：答案空间。
一个算法的最坏复杂度 等于 一个问题的复杂度的下界，则此算法最优。

顺序搜索乱序数组的平均复杂度：
如果目标元素在数组里，出现在每个位置的概率相同，则搜索次数 = sum(i+1) / n = (n+1)/2
如果不在数组里，则搜索n次。设在的概率为q，则不在的概率为(1-q)。总次数：二者与概率相乘再相加。

顺序搜索有序数组：成功时不变；失败时有 早返回 优化，只要cur>target就知道没找到。
n个存在的元素将值域划分出了n+1个区间，假设落入每个区间的概率相等，落在第一个区间就找不到的比较次数时1，依次到n-1，大约n/2

二分搜索在有序数组中的最优性：
前提：算法只能通过比较操作来获取信息。
从信息论的视角：在一个长度为n的数组中查找某个元素，等价于在一个大小为n的集合中确定一个特定元素的位置。每次比较最多能提供1b的信息，所需最少比较次数logn。
BS每次将问题规模减半，搜索过程形成一棵二叉树结构（决策树），其高度为logn。无论是最坏还是平均，无论是成功还是失败，BS的次数都是大约logn。
平均复杂度：对于一个BST，根要比较1次，第二层比较2次，且有2个元素，第三次3次，且有4个元素。假设高k，n=2^k-1，选每个元素概率相等，总次数=1/n ∑(t=1 -> k) t*2^(t-1)。用差比数列求和。

基于比较的排序算法：
对于n个元素的数组，排列顺序有n!种；其决策树最小高度为log(n!)。根据 斯特林公式，log(n!) ≈ nlogn - n + o(n)

2. O、Ω、θ

它们都是集合

n->∞ 时
f/g = c < ∞，则f ∈ O(g)，即f不如g增长快（或一样快）；其中c可以为0，此时称f∈o(g)。另一种形式（定义）：对于n>n0和某一常数c>0，有f <= cg。O一般读作big-O，o读作little-o；其实是omicron
f/g > 0， 则f ∈ Ω(g)，即f至少和g增长一样快；其中包括∞。若为∞，称f∈w(g)。定义：f >= cg
f/g = c，其中 0 < c < 无穷，则f ∈ θ(g)，称为 f是g的渐进阶或阶。f与g增长一样快
性质：
它们都是传递的
f∈O(g) <=> g∈Ω(f)  证明：根据定义，一个方向的c是另一个方向的1/c
O(f+g) = O(max(f,g))  证明：f+g∈O(max(f,g)) 且 max(f,g)∈O(f+g)，根据定义分别取c=2和c=1，即 max(f,g) < f+g < 2max(f,g)
O(f)+O(g) = O(max(f,g))  证明：左推右，设任意h1∈O(f)，h2∈O(g)，有h1<=c1f, h2<=c2g，两边相加，又显然f,g<=max(f,g)，则c1f+c2g<=(c1+c2)max(f,g)

3. 特征方程解递推式（没考）

对于an = r1 * an-1 + r2 * an-2。
设存在一个解是x^n，带入得x² - r1x - r2 = 0，解得两个根s1 s2。
如果不等，则 an = u*s1^n + v*s2^n；如果相等，则an = (u+vn)s^n。其中u v是待定系数。
再代入a1 a2确定u v
证明正确性：u*s1^n + v*s2^n = an = r1 * an-1 + r2 * an-2，左边对s1 s2拆出平方，代入x² = r1x+r2，重新组合成右边

4. 决策树、平滑函数、主定理Master Theorem

如T(n) = 2T(n/2) + n，假设n是偶数。
决策树：从根开始，标记当前规模T(n)和合并成本n，再分成两份。第二层两个节点规模T(n/2)，该层合并总成本仍为n，即每一层都是n。树高logn+1，相乘得n(logn+1)。
例如T(n) = 3T(n/4) + θ(n²)。先把后者变为cn²。根层cn²，下一层分成三份，每一份规模T(n/4)，合并成本把n/4代入后者再乘3得3/16cn²。再下一层(3/16)²cn²
TODO:未完成

逐步展开：每次将子规模代入T(n)，展开整理，变为 参数 * T(子子规模) + 非递归部分1 + 非递归部分2，即要把T的参数合并，而非递归部分不合并。展开到最后 T(最小规模)，令 最小规模 = 1，其中最小规模含有展开次数k，非递归部分也与k有关，解出k代入即为结果，T(1)忽略

主定理：对于T(n)=aT(n/b)+f(n)，其中a>=1,b>1。每次划分a个子问题，每个大小是原来的1/b，分解和合并花费f(n)
比较递归部分的增长率（先计算E=logb(a)也等于lga/lgb，其增长率为n^E）和非递归部分的增长率（f(n)的n^几次）
前者的推导过程：设树深D，则n/(b^D)=1，b^D=n，两边取lg，得D=lgn/lgb。设叶子数L，则L=a^D，变换=n^(lga/lgn*D)=n^(lga/lgb)
如果 递归 > 非递归（正式表述：f(n)∈O(n^(E-ε)，ε>0)），则T(n)∈θ(n^E) 即以递归为准
如果 ==（正式表述：f(n)∈θ(n^E)），则T(n)∈θ(f(n)logn)
如果 <（正式表述：f(n)∈Ω(n^(E+ε)，ε>0)），且满足 a*f(n/b) <= c*f(n) 对某个c<1成立（或且满足 f(n)∈O(n^(E+δ)，δ>ε)），则T(n)∈θ(f(n))。如a=b=2，E=1，f(n)=nlogn，则c==1，不适用

smooth函数：f(n)非负且最终非减，如果f(2n)∈θ(f(n))即c1f <= f(2n) <= c2f（或验证二者之比的极限），则f(n)是smooth函数
logn n nlogn是，2^n不是
对一个smooth函数，任意b>=2都有f(bn)∈θ(f(n))。b=2^k时也成立，可根据定义依次翻倍推出。
在递推中的使用：可以假定输入规模是2^k

5. 堆

堆结构：h-1层满。叶只在h-1层和h层，且h层的叶都在h-1层的左边
偏序性质：任意父>=子（或<=）
满足这两条就是堆

用数组表示堆：从1开始作为起点
堆上操作：寻父、寻子

6. 快排中的复杂度分析

设A(n)表示处理n个元素的平均复杂度。确定pivot最终位置时，无论在哪里，都要n-1次比较。然后在每个位置都可能产生划分，概率1/n。划分后分别处理A(i)和A(n-1-i)。又它具有对称性。
整理得A(n) = (n-1) + 2/n * ∑(i=1 -> n-1) A(i)
代入n-1得A(n) = 另一个式子
再计算另一个式子 nA(n) - (n-1)A(n-1)，代入上面两式，其中那两个求和相减得到 2A(n-1)，本式=2(n-1)+2A(n-1)
将上式左边的减项移到右边，得 nA(n) = (n+1)A(n-1) + 2(n-1)，两边除以n(n+1)，得 A(n)/(n+1) = A(n-1)/n + 2(n-1)/n(n+1)
令左边等于B(n)，则B(n) = B(n-1) + O(1/n)。求和（对1/n积分得ln）得B(n)∈O(logn)，则An∈O(nlogn)

7. 对抗策略、同时求最大最小、求第二大

同时找到最大值和最小值：两两配对比较。对每一对先进行一次比较，得到较小者和较大者。将较小者与当前最小值比较，较大者与当前最大值比较。这样每两个元素之间只需3次比较。另一种理解方式：两两配对分组为较大者和较小者，需要n/2次比较（假设为偶数）；再用正常方式各一轮遍历所有的较大者、所有较小者，需要2(n/2-1)次比较；一共3n/2 - 2 次比较，而不是2(n-1)次比较。如果为奇数，取前n-1个元素配对，第二轮各自比完再与剩下的那一个比一下。

第二大：
如果用两次扫描，第一次比较n-1，第二次比较n-2，合计2n-3
锦标赛：任何找到第二大的算法都必须先找到最大的。在输给最大值的集合中找最大值。最大值最多比n-1次，输给最大值的数量是树的高度logn，在其中选最大值最多比它-1次，合计n+logn-2

对抗策略：描述算法在获取信息中走的更差的路，迫使算法做出更多决策（如比较），通过走更差路模拟最坏复杂度。
在最大最小中的策略：证明任何算法在最坏情况下都至少需要3n/2-2次比较。比较两个数时，如果有个只赢过，就继续让它赢；如果有个只输过，就继续让它输。最终只有二者没比过的才会获得2份信息，其他状态最多只会获得1份；至少需要n-1份赢信息和n-1份输信息，通过n/2次比较获得了n份信息，2n-2-n=n-2份信息必须比较这么多次，因此下界是3n/2-2

Weighted Key：n个数初始财富都为1，两个数比较，算法让其中一个赢，赢的那个把输的财富拿走，到n时结束。策略：总让财富多的赢。

8. 平摊分析的含义、解决MultiPop Stack和DeleteLargerHalf

单次操作的最坏情况，无法准确反映一系列操作的平均性能。在一个操作序列中，高成本操作的出现频率足够低，其成本可以被大量低成本操作“分摊”掉。
使得任意长度的操作序列的总时间的上界是 序列长度 × AmortizedCost。但它不保证单次操作的时间

聚合分析 计算方式（不考）：计算所有操作最坏实际总成本，再除以n

核算法 一定要写出公式 均摊等式：平摊耗费AmortizedCost = 实际耗费ActualCost + 会计耗费AccountingCost

MultiPop：本来push时耗费1，MultiPop时与n有关。平摊后，push时先花费2，把pop的1提前算进去了；pop会计耗费-1；MultiPop是多次Pop，而Pop现在花费0。因此单个操作都是O(1)。约束（前提）：原本是空栈

DeleteLargerHalf：对于一个集合，支持两种操作，插入、删去最大的一半。
不均摊：插入1；删除O(n)，假设为tn，t是常数。
会计成本：让单次插入花费2t，让单词删除花费-tn。要说明会计耗费之和>=0：对于n个元素，删除的n/2个元素在插入时有tn的会计成本，因此>=0
均摊：插入花费1+2t，删除花费0

9. DFS、BFS的思想。解决：拓扑序、任务调度、关键路径、强连通区域

DFS：从起始节点出发，尽可能深入地访问每一个分支，直到不能再继续为止，然后回溯到上一个未访问完的节点，继续深入。
BFS：按层依次访问其所有邻接节点，再逐层向外扩展。
白色：未被访问。灰色（在栈中）：已访问但有邻接结点未访问完。黑色：此结点及其在生成树中对应的子结点已被访问。

环检测：遇到灰色结点。

强连通区域（考）：该子图中的每一个结点都有到另一个节点的路径
压缩图：一定无环，否则会合并进一个强连通区域
在dfs搜索中，一个强连通区域一定在一个dfs搜索树上，反之不成立，一个dfs树上可能有多个强连通区域

10. 贪心法的思想和特点。解决：换硬币、活动安排

贪心选择性质（做出局部最优选择，得到的结果是全局最优）、最优子结构性质（一个问题的最优解包含其子问题的最优解）、无状态不回溯、高效。

证：先构造一个贪心算法的解。再构造一个最优解。算法解可以通过某种方式转换成最优解的解，有对应关系，是最优解中的一个
把最优解设出来，对最优解进行观察形成一个约束。如每个面值的硬币个数。其中小面值的总和不能超过某个大面值，否则就可以换掉
对于面额最大的，贪心法的优先选大的，个数大于等于最优解。经过一些推导，反正就只能等于。对于面额第二大的同理。

另一种证明过程：
1. 描述一下贪心选择策略，如选择面额最大的硬币
2. 证明贪心选择性质：把最优解设出来，其中某个不满足贪心法的选择。构造一个新的解，替换其中某些元素，使其包含贪心选择，同时仍为最优解。如假设存在一个最优解不用当前可用的最大面额，而是使用了若干个小面额，根据一般货币系统规则，可以用那个大面额替代，从而数量更少
3. 证明最优子结构：一旦做出贪心选择，剩下的问题仍然是一个规模更小的相同问题。如选了某面额c，剩下的问题是总面额为n-c的最小硬币数。说明子问题的最优解才能导致原问题的最优解。一般就是 总 = 2 + 子，当2已经最优，只要子最优，总就最优


11. 动态规划的思想和特点。解决：最长公共子序列、最优二叉搜索树

写主要能解决什么问题。只要思想写得对就行，不用写伪代码

* 最优子结构：一个问题的最优解包含其子问题的最优解。计算出子问题的最优解后通过状态转移方程计算原问题的最优解
* 重叠子问题：反复求解相同的子问题；同时也是与分治的区别
* 无后效性：后续决策不受历史决策过程影响，只依赖状态，不依赖到达此状态的步骤。

---------
答案空间：
如14个球里面有1个坏的（轻或重），一共28种可能性。取两份相同的称一次，还剩一些没称，分成三堆，越均匀越好。如果称3次，最多能解决3^3=27个空间，因此至少要称4次。实际如果是13个球，也要称4次，因为算法实现限制，不能那么均匀。12个称3次可以，第一次分4 4 4称，结果为1-4重 5-8轻 9-12可轻可重，可能性都为8个；接下来取

算法导论习题：
https://walkccc.me/CLRS/Chap02/2.2/
